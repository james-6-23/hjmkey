#!/usr/bin/env python
"""
Token Hunter å‘½ä»¤è¡Œå·¥å…·
ç”¨äºæœç´¢ã€éªŒè¯å’Œç®¡ç†GitHub tokens
"""

import os
import argparse
import json
import logging
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

from utils.token_hunter import TokenHunter, TokenManager, TokenValidator

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)


def get_proxy_config():
    """
    ä»ç¯å¢ƒå˜é‡è·å–ä»£ç†é…ç½®
    
    Returns:
        ä»£ç†é…ç½®å­—å…¸æˆ–None
    """
    # å°è¯•ä»PROXYç¯å¢ƒå˜é‡è¯»å–
    proxy_str = os.getenv("PROXY", "").strip()
    
    if proxy_str:
        # å¦‚æœæœ‰å¤šä¸ªä»£ç†ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
        proxies = [p.strip() for p in proxy_str.split(',') if p.strip()]
        if proxies:
            proxy_url = proxies[0]
            logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
            return {
                'http': proxy_url,
                'https': proxy_url
            }
    
    # ä¹Ÿæ”¯æŒæ ‡å‡†çš„HTTP_PROXYå’ŒHTTPS_PROXYç¯å¢ƒå˜é‡
    http_proxy = os.getenv("HTTP_PROXY") or os.getenv("http_proxy")
    https_proxy = os.getenv("HTTPS_PROXY") or os.getenv("https_proxy")
    
    if http_proxy or https_proxy:
        proxy_config = {}
        if http_proxy:
            proxy_config['http'] = http_proxy
            logger.info(f"ğŸŒ ä½¿ç”¨HTTPä»£ç†: {http_proxy}")
        if https_proxy:
            proxy_config['https'] = https_proxy
            logger.info(f"ğŸŒ ä½¿ç”¨HTTPSä»£ç†: {https_proxy}")
        return proxy_config
    
    return None


def search_tokens(args):
    """æœç´¢tokens"""
    print("ğŸ” å¼€å§‹æœç´¢GitHub Tokens...")
    
    # è·å–ä»£ç†é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
    proxy = get_proxy_config() if not args.no_proxy else None
    
    hunter = TokenHunter(
        github_token=args.github_token,
        tokens_file=args.tokens_file,
        auto_save=args.auto_save,
        proxy=proxy
    )
    
    results = hunter.hunt_tokens(
        mode=args.mode,
        validate=args.validate,
        max_results=args.max_results
    )
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š æœç´¢ç»“æœ:")
    print(f"  æ€»å…±æ‰¾åˆ°: {results['statistics']['total_found']} ä¸ªtokens")
    
    if args.validate:
        print(f"  æœ‰æ•ˆtokens: {results['statistics'].get('valid_count', 0)} ä¸ª")
        print(f"  æ— æ•ˆtokens: {results['statistics'].get('invalid_count', 0)} ä¸ª")
        
        if results['valid_tokens'] and args.show_tokens:
            print("\nâœ… æœ‰æ•ˆtokens:")
            for i, token in enumerate(results['valid_tokens'], 1):
                print(f"  {i}. {token[:20]}...")
    
    if args.output:
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")


def validate_tokens(args):
    """éªŒè¯tokens"""
    print("ğŸ” å¼€å§‹éªŒè¯tokens...")
    
    if args.input_file:
        # ä»æ–‡ä»¶è¯»å–tokens
        tokens = []
        with open(args.input_file, 'r') as f:
            for line in f:
                token = line.strip()
                if token and not token.startswith('#'):
                    tokens.append(token)
        print(f"ä» {args.input_file} åŠ è½½äº† {len(tokens)} ä¸ªtokens")
    else:
        # éªŒè¯ç®¡ç†å™¨ä¸­çš„tokens
        manager = TokenManager(args.tokens_file)
        tokens = manager.tokens
        print(f"ä» {args.tokens_file} åŠ è½½äº† {len(tokens)} ä¸ªtokens")
    
    if not tokens:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°tokens")
        return
    
    # è·å–ä»£ç†é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
    proxy = get_proxy_config() if not args.no_proxy else None
    
    # éªŒè¯tokens
    validator = TokenValidator(proxy=proxy)
    valid_count = 0
    invalid_count = 0
    
    print(f"\néªŒè¯è¿›åº¦:")
    for i, token in enumerate(tokens, 1):
        result = validator.validate(token)
        
        if result.valid:
            valid_count += 1
            status = "âœ… æœ‰æ•ˆ"
            extra = f"ç”¨æˆ·: {result.user}, é¢åº¦: {result.rate_limit.remaining}/{result.rate_limit.limit}" if result.rate_limit else ""
        else:
            invalid_count += 1
            status = "âŒ æ— æ•ˆ"
            extra = f"åŸå› : {result.reason}"
        
        print(f"  [{i}/{len(tokens)}] {token[:20]}... - {status} {extra}")
    
    print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
    print(f"  æœ‰æ•ˆ: {valid_count} ä¸ª")
    print(f"  æ— æ•ˆ: {invalid_count} ä¸ª")


def manage_tokens(args):
    """ç®¡ç†tokens"""
    manager = TokenManager(args.tokens_file)
    
    if args.action == 'list':
        # åˆ—å‡ºæ‰€æœ‰tokens
        print(f"ğŸ“‹ å½“å‰æœ‰ {len(manager.tokens)} ä¸ªtokens:")
        for i, token in enumerate(manager.tokens, 1):
            print(f"  {i}. {token[:20]}...")
    
    elif args.action == 'add':
        # æ·»åŠ token
        if args.token:
            success = manager.add_token(args.token, validate=not args.no_validate)
            if success:
                print(f"âœ… æˆåŠŸæ·»åŠ token")
            else:
                print(f"âŒ æ·»åŠ tokenå¤±è´¥")
        else:
            print("âŒ è¯·æä¾›è¦æ·»åŠ çš„token")
    
    elif args.action == 'remove':
        # ç§»é™¤token
        if args.token:
            success = manager.remove_token(args.token)
            if success:
                print(f"âœ… æˆåŠŸç§»é™¤token")
            else:
                print(f"âŒ ç§»é™¤tokenå¤±è´¥")
        else:
            print("âŒ è¯·æä¾›è¦ç§»é™¤çš„token")
    
    elif args.action == 'status':
        # æ˜¾ç¤ºçŠ¶æ€
        status = manager.get_status()
        print(f"\nğŸ“Š Tokenç®¡ç†å™¨çŠ¶æ€:")
        print(f"  æ€»tokensæ•°: {status['total_tokens']}")
        print(f"  å½“å‰ç´¢å¼•: {status['current_index']}")
        print(f"  æ–‡ä»¶è·¯å¾„: {status['tokens_file']}")
        
        if status['stats']:
            print(f"\n  å„tokené¢åº¦çŠ¶æ€:")
            for token_key, info in status['stats'].items():
                if 'remaining' in info:
                    print(f"    {token_key}: {info['remaining']}/{info['limit']} (ä½¿ç”¨ç‡: {info['usage']})")
                else:
                    print(f"    {token_key}: {info['status']}")
    
    elif args.action == 'validate':
        # éªŒè¯æ‰€æœ‰tokens
        print("ğŸ” éªŒè¯æ‰€æœ‰tokens...")
        results = manager.validate_all_tokens()
        
        valid_count = sum(1 for r in results.values() if r.valid)
        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"  æœ‰æ•ˆ: {valid_count}/{len(results)} ä¸ª")
        
        for token_key, result in results.items():
            if result.valid:
                print(f"  âœ… {token_key}: æœ‰æ•ˆ")
            else:
                print(f"  âŒ {token_key}: {result.reason}")
    
    elif args.action == 'clear':
        # æ¸…ç©ºæ‰€æœ‰tokens
        if input("âš ï¸ ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰tokenså—ï¼Ÿ(yes/no): ").lower() == 'yes':
            manager.clear_all_tokens()
            print("âœ… å·²æ¸…ç©ºæ‰€æœ‰tokens")
        else:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")


def hunt_and_add(args):
    """æœç´¢å¹¶è‡ªåŠ¨æ·»åŠ tokens"""
    print("ğŸ¯ å¼€å§‹æœç´¢å¹¶æ·»åŠ tokens...")
    
    # è·å–ä»£ç†é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
    proxy = get_proxy_config() if not args.no_proxy else None
    
    hunter = TokenHunter(
        github_token=args.github_token,
        tokens_file=args.tokens_file,
        auto_save=True,
        proxy=proxy
    )
    
    results = hunter.hunt_and_add(
        mode=args.mode,
        max_results=args.max_results
    )
    
    print(f"\nğŸ“Š æ“ä½œç»“æœ:")
    print(f"  æ‰¾åˆ°tokens: {results['statistics']['total_found']} ä¸ª")
    print(f"  æœ‰æ•ˆtokens: {results['statistics'].get('valid_count', 0)} ä¸ª")
    
    if 'add_results' in results:
        success_count = sum(1 for v in results['add_results'].values() if v)
        print(f"  æˆåŠŸæ·»åŠ : {success_count} ä¸ª")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Token Hunter - GitHub Tokenæœç´¢å’Œç®¡ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æœç´¢æœ¬åœ°tokens
  python cli.py search --mode local
  
  # æœç´¢GitHubå¹¶éªŒè¯
  python cli.py search --mode github --validate --github-token YOUR_TOKEN
  
  # éªŒè¯tokensæ–‡ä»¶
  python cli.py validate --input-file tokens.txt
  
  # ç®¡ç†tokens
  python cli.py manage list
  python cli.py manage add --token ghp_xxxxx
  python cli.py manage status
  
  # æœç´¢å¹¶è‡ªåŠ¨æ·»åŠ 
  python cli.py hunt --mode all --max-results 50
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # searchå‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢tokens')
    search_parser.add_argument('--mode', choices=['github', 'local', 'all'], default='all',
                              help='æœç´¢æ¨¡å¼ (é»˜è®¤: all)')
    search_parser.add_argument('--validate', action='store_true',
                              help='éªŒè¯æ‰¾åˆ°çš„tokens')
    search_parser.add_argument('--max-results', type=int, default=100,
                              help='æœ€å¤§ç»“æœæ•° (é»˜è®¤: 100)')
    search_parser.add_argument('--github-token', help='ç”¨äºGitHubæœç´¢çš„token')
    search_parser.add_argument('--tokens-file', default='data/github_tokens.txt',
                              help='tokensä¿å­˜æ–‡ä»¶ (é»˜è®¤: data/github_tokens.txt)')
    search_parser.add_argument('--auto-save', action='store_true',
                              help='è‡ªåŠ¨ä¿å­˜æœ‰æ•ˆtokens')
    search_parser.add_argument('--show-tokens', action='store_true',
                              help='æ˜¾ç¤ºæ‰¾åˆ°çš„tokens')
    search_parser.add_argument('--output', help='ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶')
    search_parser.add_argument('--no-proxy', action='store_true',
                              help='ä¸ä½¿ç”¨ä»£ç†ï¼ˆå³ä½¿ç¯å¢ƒå˜é‡ä¸­é…ç½®äº†ä»£ç†ï¼‰')
    
    # validateå‘½ä»¤
    validate_parser = subparsers.add_parser('validate', help='éªŒè¯tokens')
    validate_parser.add_argument('--input-file', help='è¦éªŒè¯çš„tokensæ–‡ä»¶')
    validate_parser.add_argument('--tokens-file', default='data/github_tokens.txt',
                                help='tokensæ–‡ä»¶ (é»˜è®¤: data/github_tokens.txt)')
    validate_parser.add_argument('--no-proxy', action='store_true',
                                help='ä¸ä½¿ç”¨ä»£ç†ï¼ˆå³ä½¿ç¯å¢ƒå˜é‡ä¸­é…ç½®äº†ä»£ç†ï¼‰')
    
    # manageå‘½ä»¤
    manage_parser = subparsers.add_parser('manage', help='ç®¡ç†tokens')
    manage_parser.add_argument('action', choices=['list', 'add', 'remove', 'status', 'validate', 'clear'],
                              help='ç®¡ç†æ“ä½œ')
    manage_parser.add_argument('--token', help='è¦æ“ä½œçš„token')
    manage_parser.add_argument('--tokens-file', default='data/github_tokens.txt',
                              help='tokensæ–‡ä»¶ (é»˜è®¤: data/github_tokens.txt)')
    manage_parser.add_argument('--no-validate', action='store_true',
                              help='æ·»åŠ æ—¶ä¸éªŒè¯token')
    
    # huntå‘½ä»¤ (æœç´¢å¹¶æ·»åŠ )
    hunt_parser = subparsers.add_parser('hunt', help='æœç´¢å¹¶è‡ªåŠ¨æ·»åŠ tokens')
    hunt_parser.add_argument('--mode', choices=['github', 'local', 'all'], default='all',
                            help='æœç´¢æ¨¡å¼ (é»˜è®¤: all)')
    hunt_parser.add_argument('--max-results', type=int, default=50,
                            help='æœ€å¤§ç»“æœæ•° (é»˜è®¤: 50)')
    hunt_parser.add_argument('--github-token', help='ç”¨äºGitHubæœç´¢çš„token')
    hunt_parser.add_argument('--tokens-file', default='data/github_tokens.txt',
                            help='tokensæ–‡ä»¶ (é»˜è®¤: data/github_tokens.txt)')
    hunt_parser.add_argument('--no-proxy', action='store_true',
                            help='ä¸ä½¿ç”¨ä»£ç†ï¼ˆå³ä½¿ç¯å¢ƒå˜é‡ä¸­é…ç½®äº†ä»£ç†ï¼‰')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == 'search':
            search_tokens(args)
        elif args.command == 'validate':
            validate_tokens(args)
        elif args.command == 'manage':
            manage_tokens(args)
        elif args.command == 'hunt':
            hunt_and_add(args)
    except KeyboardInterrupt:
        print("\nâ›” æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()