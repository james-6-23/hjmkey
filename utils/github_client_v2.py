"""
GitHub å®¢æˆ·ç«¯ V2 - é›†æˆ TokenPool çš„å¢å¼ºç‰ˆ
"""

import base64
import random
import time
import logging
from typing import Dict, List, Optional, Any, Tuple
import requests
from utils.token_pool import TokenPool, TokenSelectionStrategy
from utils.security_utils import mask_key

logger = logging.getLogger(__name__)


class GitHubClientV2:
    """å¢å¼ºç‰ˆ GitHub å®¢æˆ·ç«¯ï¼Œé›†æˆ TokenPool"""
    
    GITHUB_API_URL = "https://api.github.com/search/code"
    
    def __init__(self, token_pool: TokenPool):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            token_pool: TokenPool å®ä¾‹
        """
        self.token_pool = token_pool
        self.session = requests.Session()
        
        # ç»Ÿè®¡
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        
        logger.info(f"ğŸŒ GitHub Client V2 initialized with token pool")
    
    def search_for_keys(self, query: str, max_retries: int = 5) -> Dict[str, Any]:
        """
        æœç´¢å¯†é’¥
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            æœç´¢ç»“æœ
        """
        all_items = []
        total_count = 0
        expected_total = None
        pages_processed = 0
        
        # æ·»åŠ å¤±è´¥é¡µé¢é‡è¯•é˜Ÿåˆ—
        failed_pages = []
        max_page_retries = 2
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_requests = 0
        failed_requests = 0
        rate_limit_hits = 0
        
        for page in range(1, 11):  # æœ€å¤š10é¡µ
            page_result = None
            page_success = False
            
            for attempt in range(1, max_retries + 1):
                # ä» TokenPool è·å–ä»¤ç‰Œ
                token = self.token_pool.select_token()
                if not token:
                    logger.error("âŒ No available tokens in pool")
                    time.sleep(5)  # ç­‰å¾…ä»¤ç‰Œæ¢å¤
                    continue
                
                # æ„å»ºè¯·æ±‚
                headers = {
                    "Accept": "application/vnd.github.v3+json",
                    "User-Agent": "Mozilla/5.0 (compatible; HajimiKing/2.0)",
                    "Authorization": f"token {token}"
                }
                
                params = {
                    "q": query,
                    "per_page": 100,
                    "page": page
                }
                
                try:
                    total_requests += 1
                    self.total_requests += 1
                    
                    # å‘é€è¯·æ±‚
                    start_time = time.time()
                    response = self.session.get(
                        self.GITHUB_API_URL, 
                        headers=headers, 
                        params=params, 
                        timeout=30
                    )
                    response_time = time.time() - start_time
                    
                    # æ›´æ–° TokenPool
                    self.token_pool.update_token_status(token, {
                        'status_code': response.status_code,
                        'headers': dict(response.headers),
                        'response_time': response_time
                    })
                    
                    # æ£€æŸ¥å“åº”
                    if response.status_code == 200:
                        page_result = response.json()
                        page_success = True
                        self.successful_requests += 1
                        
                        # è®°å½•é™æµä¿¡æ¯
                        remaining = response.headers.get('X-RateLimit-Remaining')
                        if remaining and int(remaining) < 5:
                            logger.warning(f"âš ï¸ Low quota: {remaining} remaining for {mask_key(token)}")
                        
                        break
                    
                    elif response.status_code in (403, 429):
                        # é™æµ
                        rate_limit_hits += 1
                        self.failed_requests += 1
                        logger.warning(f"ğŸš« Rate limited (attempt {attempt}/{max_retries})")
                        
                        # å¿«é€Ÿåˆ‡æ¢ä»¤ç‰Œ
                        if attempt < max_retries:
                            time.sleep(1)  # çŸ­æš‚ç­‰å¾…
                            continue
                    
                    else:
                        # å…¶ä»–é”™è¯¯
                        self.failed_requests += 1
                        logger.error(f"âŒ HTTP {response.status_code} (attempt {attempt}/{max_retries})")
                        
                        if attempt < max_retries:
                            time.sleep(min(2 ** attempt, 10))
                            continue
                
                except requests.exceptions.RequestException as e:
                    failed_requests += 1
                    self.failed_requests += 1
                    
                    if attempt == max_retries:
                        logger.error(f"âŒ Request failed after {max_retries} attempts: {type(e).__name__}")
                    
                    time.sleep(min(2 ** attempt, 10))
                    continue
            
            # å¤„ç†é¡µé¢ç»“æœ
            if not page_success or not page_result:
                if page == 1:
                    logger.error(f"âŒ First page failed for query: {query[:50]}...")
                    break
                else:
                    # åŠ å…¥é‡è¯•é˜Ÿåˆ—
                    failed_pages.append({'page': page, 'retry_count': 0})
                    logger.debug(f"ğŸ“ Page {page} added to retry queue")
                continue
            
            pages_processed += 1
            
            # å¤„ç†ç¬¬ä¸€é¡µ
            if page == 1:
                total_count = page_result.get("total_count", 0)
                expected_total = min(total_count, 1000)  # GitHub é™åˆ¶æœ€å¤š1000ä¸ªç»“æœ
                logger.info(f"ğŸ” Query: {query} - Total results: {total_count}")
            
            # æ”¶é›†é¡¹ç›®
            items = page_result.get("items", [])
            current_page_count = len(items)
            
            if current_page_count == 0:
                break
            
            all_items.extend(items)
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if expected_total and len(all_items) >= expected_total:
                break
            
            # é¡µé¢é—´å»¶è¿Ÿ
            if page < 10:
                sleep_time = random.uniform(0.5, 1.5)
                logger.debug(f"â³ Page {page} complete, sleeping {sleep_time:.1f}s")
                time.sleep(sleep_time)
        
        # é‡è¯•å¤±è´¥çš„é¡µé¢
        if failed_pages and expected_total:
            logger.info(f"ğŸ”„ Retrying {len(failed_pages)} failed pages...")
            
            for failed_page_info in failed_pages[:]:
                if failed_page_info['retry_count'] >= max_page_retries:
                    continue
                
                page = failed_page_info['page']
                failed_page_info['retry_count'] += 1
                
                # ç­‰å¾…åé‡è¯•
                time.sleep(2 * failed_page_info['retry_count'])
                
                # ç®€åŒ–çš„é‡è¯•é€»è¾‘
                token = self.token_pool.select_token()
                if token:
                    try:
                        headers = {
                            "Accept": "application/vnd.github.v3+json",
                            "Authorization": f"token {token}"
                        }
                        params = {"q": query, "per_page": 100, "page": page}
                        
                        response = self.session.get(
                            self.GITHUB_API_URL, 
                            headers=headers, 
                            params=params, 
                            timeout=30
                        )
                        
                        if response.status_code == 200:
                            retry_result = response.json()
                            items = retry_result.get("items", [])
                            if items:
                                all_items.extend(items)
                                pages_processed += 1
                                failed_pages.remove(failed_page_info)
                                logger.info(f"âœ… Recovered page {page} with {len(items)} items")
                    
                    except Exception as e:
                        logger.debug(f"Failed to recover page {page}: {type(e).__name__}")
        
        # è®¡ç®—æ•°æ®å®Œæ•´æ€§
        final_count = len(all_items)
        if expected_total and final_count < expected_total:
            completeness = (final_count / expected_total) * 100
            if completeness < 90:
                logger.warning(f"âš ï¸ Data completeness: {completeness:.1f}% ({final_count}/{expected_total})")
        
        # è®°å½•æ‘˜è¦
        logger.info(
            f"ğŸ” Search complete: query={query[:30]}... | "
            f"pages={pages_processed} | items={final_count}/{expected_total or '?'} | "
            f"requests={total_requests} | rate_limits={rate_limit_hits}"
        )
        
        return {
            "total_count": total_count,
            "incomplete_results": final_count < expected_total if expected_total else False,
            "items": all_items,
            "statistics": {
                "pages_processed": pages_processed,
                "total_requests": total_requests,
                "failed_requests": failed_requests,
                "rate_limit_hits": rate_limit_hits
            }
        }
    
    def get_file_content(self, item: Dict[str, Any]) -> Optional[str]:
        """
        è·å–æ–‡ä»¶å†…å®¹
        
        Args:
            item: æœç´¢ç»“æœé¡¹
            
        Returns:
            æ–‡ä»¶å†…å®¹æˆ– None
        """
        repo_full_name = item["repository"]["full_name"]
        file_path = item["path"]
        metadata_url = f"https://api.github.com/repos/{repo_full_name}/contents/{file_path}"
        
        # è·å–ä»¤ç‰Œ
        token = self.token_pool.select_token()
        if not token:
            logger.error("âŒ No available token for file content")
            return None
        
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "Authorization": f"token {token}"
        }
        
        try:
            logger.debug(f"ğŸ“„ Fetching: {metadata_url}")
            
            # è·å–æ–‡ä»¶å…ƒæ•°æ®
            start_time = time.time()
            metadata_response = self.session.get(metadata_url, headers=headers, timeout=15)
            response_time = time.time() - start_time
            
            # æ›´æ–° TokenPool
            self.token_pool.update_token_status(token, {
                'status_code': metadata_response.status_code,
                'headers': dict(metadata_response.headers),
                'response_time': response_time
            })
            
            if metadata_response.status_code != 200:
                logger.warning(f"âš ï¸ Failed to fetch metadata: HTTP {metadata_response.status_code}")
                return None
            
            file_metadata = metadata_response.json()
            
            # å°è¯• base64 å†…å®¹
            encoding = file_metadata.get("encoding")
            content = file_metadata.get("content")
            
            if encoding == "base64" and content:
                try:
                    decoded_content = base64.b64decode(content).decode('utf-8')
                    return decoded_content
                except Exception as e:
                    logger.debug(f"Base64 decode failed: {e}")
            
            # ä½¿ç”¨ download_url
            download_url = file_metadata.get("download_url")
            if download_url:
                content_response = self.session.get(download_url, headers=headers, timeout=15)
                if content_response.status_code == 200:
                    return content_response.text
            
            return None
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ Failed to fetch file content: {type(e).__name__}")
            return None
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–å®¢æˆ·ç«¯ç»Ÿè®¡"""
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "success_rate": (
                self.successful_requests / self.total_requests 
                if self.total_requests > 0 else 0
            ),
            "token_pool_status": self.token_pool.get_pool_status()
        }
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        self.session.close()
        logger.info("ğŸ”Œ GitHub Client V2 closed")


# å·¥å‚å‡½æ•°
def create_github_client_v2(tokens: List[str], 
                           strategy: str = "ADAPTIVE") -> GitHubClientV2:
    """
    åˆ›å»º GitHub å®¢æˆ·ç«¯ V2
    
    Args:
        tokens: GitHub ä»¤ç‰Œåˆ—è¡¨
        strategy: TokenPool ç­–ç•¥
        
    Returns:
        GitHubClientV2 å®ä¾‹
    """
    # åˆ›å»º TokenPool
    strategy_enum = TokenSelectionStrategy[strategy.upper()]
    token_pool = TokenPool(tokens, strategy=strategy_enum)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    return GitHubClientV2(token_pool)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import os
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(name)s | %(message)s'
    )
    
    # æµ‹è¯•ä»¤ç‰Œ
    test_tokens = [
        "github_pat_11AAAAAAA" + "A" * 74,
        "github_pat_11BBBBBBBB" + "B" * 74,
    ]
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = create_github_client_v2(test_tokens, strategy="ADAPTIVE")
    
    # æµ‹è¯•æœç´¢
    result = client.search_for_keys("test query", max_retries=3)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats = client.get_statistics()
    print("\nğŸ“Š Client Statistics:")
    for key, value in stats.items():
        if key != "token_pool_status":
            print(f"  {key}: {value}")
    
    # å…³é—­
    client.close()